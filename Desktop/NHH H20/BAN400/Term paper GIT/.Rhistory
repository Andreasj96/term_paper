library(tm)
library(wordcloud)
cleaning_tw_df(tw_df)
cleaned_tw
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)%>%           #remove hashtags
removeWords(.,extra_ticker)%>%            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
print(cleaned_tw)
return(cleaned_tw)
}
cleaning_tw_df(tw_df)
cleaned_tw
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)%>%           #remove hashtags
removeWords(.,extra_ticker)%>%            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
print(cleaned_tw)
}
cleaned_tw <- cleaning_tw_df(tw_df)
cleaned_tw
make_wordcloud(cleaned_tw)
make_wordcloud<- function(df){
x <-
DocumentTermMatrix(VCorpus(VectorSource(df)),
control = list(stemming = T,
bounds = list(global = c(1,800)))) %>%
as.matrix()%>%
as.data.frame()%>%
colSums(dtm.df)
plot_wordcloud <-
wordcloud(words = names(x),
freq = x,
min.freq =5)
print(plot_wordcloud)
}
make_wordcloud(cleaned_tw)
make_wordcloud<- function(df){
x <-
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list(stemming = T,
bounds = list(global = c(1,800)))) %>%
as.matrix()%>%
as.data.frame()%>%
colSums(dtm.df)
plot_wordcloud <-
wordcloud(words = names(x),
freq = x,
min.freq =5)
print(plot_wordcloud)
}
make_wordcloud(cleaned_tw)
DocumentTermMatrix(Corpus(VectorSource(cleaned_tw)),
control = list(stemming = T,
bounds = list(global = c(1,800)))) %>%
as.matrix()%>%
as.data.frame()
DocumentTermMatrix(Corpus(VectorSource(cleaned_tw)),
control = list(stemming = T,
bounds = list(global = c(1,800))))
DocumentTermMatrix(Corpus(VectorSource(cleaned_tw)),
control = list(stemming = T,
bounds = list(global = c(1,800)))) %>%
as.matrix()%>%
as.data.frame()
cleaned_tw
a <- DocumentTermMatrix(Corpus(VectorSource(cleaned_tw)),
control = list(stemming = T,
bounds = list(global = c(5,800))))
a
view(a)
View(a)
a<- as.matrix()
b<- as.matrix(a)
c<-as.data.frame(b)
c
View(c)
colSums(c)
a <- DocumentTermMatrix(Corpus(VectorSource(cleaned_tw)),
control = list(stemming = T,
bounds = list(global = c(5,500))))
b<- as.matrix(a)
c<-as.data.frame(b)
colSums(c)
plot_wordcloud <-
wordcloud(words = names(c),
freq = c,
min.freq =5)
plot_wordcloud <-
wordcloud(words = names(c),
freq = c,
min.freq =20)
is.vector(colSums(c))
wordcloud(words = names(c),
freq = c,
min.freq =15)
d<-colSums(c)
plot_wordcloud <-
wordcloud(words = names(d),
freq = d,
min.freq =15)
plot_wordcloud <-
wordcloud(words = names(d),
freq = d,
min.freq =20)
a <- DocumentTermMatrix(Corpus(VectorSource(cleaned_tw)),
control = list(stemming = T,
bounds = list(global = c(5,800))))
b<- as.matrix(a)
c<-as.data.frame(b)
d<-colSums(c)
plot_wordcloud <-
wordcloud(words = names(d),
freq = d,
min.freq =20)
a <- DocumentTermMatrix(Corpus(VectorSource(cleaned_tw)),
control = list(stemming = T,
bounds = list(global = c(5,500))))
b<- as.matrix(a)
c<-as.data.frame(b)
d<-colSums(c)
plot_wordcloud <-
wordcloud(words = names(d),
freq = d,
min.freq =20)
make_wordcloud<- function(df){
x <-
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list(stemming = T,
bounds = list(global = c(5,500)))) %>%
as.matrix()%>%
as.data.frame()%>%
colSums()
plot_wordcloud <-
wordcloud(words = names(x),
freq = x,
min.freq =20)
print(plot_wordcloud)
}
make_wordcloud(cleaned_tw)
make_wordcloud<- function(df){
x <-
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list(stemming = T,
bounds = list(global = c(5,500)))) %>%
as.matrix()%>%
as.data.frame()%>%
colSums()
plot_wordcloud <-
wordcloud(words = names(x),
freq = x,
min.freq =20)
print(plot_wordcloud)
}
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
gsub("amp"," ", .)%>%                  #remove amp
removeWords(.,extra_hashtag)%>%        #remove hashtags
removeWords(.,extra_ticker)%>%         #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
print(cleaned_tw)
}
cleaned_tw <- cleaning_tw_df(tw_df)
make_wordcloud(cleaned_tw)
make_wordcloud<- function(df){
x <-
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list(stemming = T,
bounds = list(global = c(5,500)))) %>%
as.matrix()%>%
as.data.frame()%>%
colSums()
plot_wordcloud <-
wordcloud(words = names(x),
freq = x,
min.freq =20,
max.words = 50,
colors = brewer.pal(5, "Set1"))
print(plot_wordcloud)
}
make_wordcloud(cleaned_tw)
make_wordcloud<- function(df){
x <-
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list(stemming = T,
bounds = list(global = c(5,500)))) %>%
as.matrix()%>%
as.data.frame()%>%
colSums()
plot_wordcloud <-
wordcloud(words = names(x),
freq = x,
min.freq =20,
max.words = 50,
colors = brewer.pal(5, "Set2"))
print(plot_wordcloud)
}
make_wordcloud(cleaned_tw)
make_wordcloud<- function(df){
x <-
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list(stemming = T,
bounds = list(global = c(5,500)))) %>%
as.matrix()%>%
as.data.frame()%>%
colSums()
plot_wordcloud <-
wordcloud(words = names(x),
freq = x,
min.freq =20,
max.words = 50,
colors = brewer.pal(5, "Set1"))
print(plot_wordcloud)
}
make_wordcloud(cleaned_tw)
rm(a)
rm(b,c,d,i)
rm(q3,t3,senti.df)
rm(t4,ticker)
rm(to,x)
rm(make_dtm)
rm(extra_hash)
rm(plot_wordcloud)
rm(dict_H_negative,dict_H_positive,dict_LM_negative,dict_LM_positive,dict_LM_uncertain)
rm(DictionaryGI)
rm(test_plot)
rm(test_plot2)
getMgmtDisc(cik.no = 320193, filing.year = 2020)
#TERM PAPER BAN400
library(shiny)
library(rtweet)
library(tidyquant)
library(tidyverse)
library(dplyr)
library(SentimentAnalysis)
library(ggplot2)
library(wordcloud)
library(edgar)
library(edgarWebR)
library(riingo)
library(anytime)
library(tm)
library(wordcloud)
getMgmtDisc(cik.no = 320193, filing.year = 2020)
?getMgmtDisc
getMgmtDisc(cik.no = 320193, filing.year = 2019)
readLines("https://datafied.api.edgar-online.com/v2/companies?primarysymbols=aapl&appkey={7d405ce3e8ddb45e62da90edcc563c54}")
install.packages('GetEdgarData')
library(GetEdgarData)
install.packages("GetEdgarData")
devtools::install_github('msperlin/GetEdgarData')
output <- searchFilings(cik.no = c('1000180', '38079'),
form.type = c("10-K", "10-K405","10KSB", "10KSB40"),
filing.year = c(2005, 2006), word.list)
output <- getFilingsHTML(cik.no = 38079, '10-K',
2006, quarter = c(1, 2, 3,4))
company_filings(
x,
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10,
page = 1
)
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10,
page = 1
)
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 1
)
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203"
)
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)
?year
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
select(filing_date,href)%>%
filter(year(filing_date ) == 2020)
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
select(filing_date,href)%>%
filter(year(filing_date ) == 2020)%>%
select(href)
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)
get_url <-
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)
class(get_url)
get_url <-
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)%>%
as.vector()
get_url
class(get_url)
get_url <-
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)%>%
as.matrix()%>%
as.vector()
get_url
test_10k <- readLines(get_url)
test_10k
filing_documents(test_10k)
filing_documents(https://www.sec.gov/Archives/edgar/data/320193/000032019320000096/0000320193-20-000096-index.htm)
filing_documents("https://www.sec.gov/Archives/edgar/data/320193/000032019320000096/0000320193-20-000096-index.htm")
get_url <-
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)%>%
as.matrix()%>%
as.vector()%>%
paste0("\"",.,"\"")
get_url
get_url <-
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)%>%
as.matrix()%>%
as.vector()
filing_documents(get_url)
get_url <-
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)%>%
as.matrix()%>%
as.vector()%>%
filing_documents()%>%
filter(type == "10-K")%>%
select(href)
get_url
get_url <-
company_filings(
"AAPL",
ownership = FALSE,
type = "10-K",
before = "20201203",
count = 10
)%>%
filter(year(filing_date ) == 2020)%>%
select(href)%>%
as.matrix()%>%
as.vector()%>%
filing_documents()%>%
filter(type == "10-K")%>%
select(href)%>%
as.matrix()%>%
as.vector()
get_url
test_10k <- readLines(get_url)
