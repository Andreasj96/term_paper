library(shiny)
install.packages("rtweet")
library(rtweet)
?rtweet
?search_tweets
?search_tweets2
?shinyApp
?search_tweets
library(shiny)
library(rtweet)
?search_tweets
install.packages("twitterR")
search_tweets(
ticker_sybol,
n = 18000, #maximum
type = "recent",
include_rts = FALSE,
geocode = NULL,
max_id = NULL,
parse = TRUE,
token = NULL,
retryonratelimit = FALSE,
verbose = TRUE,
lang = "en"
)
?search_tweets
search_tweets(
"ticker_sybol",
n = 18000, #maximum
type = "recent",
include_rts = FALSE,
geocode = NULL,
max_id = NULL,
parse = TRUE,
token = NULL,
retryonratelimit = FALSE,
verbose = TRUE,
lang = "en"
)
install.packages("tidyquant")
library(tidyquant)
read.csv("us_stock_code.csv")
ticker_symbol <- read.csv("us_stock_code.csv")
View(ticker_symbol)
ticker_symbol <-
read.csv("us_stock_code.csv")%>%
select(code)
library(tidyverse)
library(dplyr)
ticker_symbol <-
read.csv("us_stock_code.csv")%>%
select(code)
View(ticker_symbol)
library(SentimentAnalysis)
runExample("01_hello")
runExample("05_sliders")
runExample("07_widgets")
st2 <- search_tweets2(
c("\"data science\"", "rstats OR python"),
n = 500
)
search_tweets(
"AAPL",
n = 1000, #maximum
type = "recent",
include_rts = FALSE,
geocode = NULL,
max_id = NULL,
parse = TRUE,
token = NULL,
retryonratelimit = FALSE,
verbose = TRUE,
lang = "en"
)
pre_df <- function(df){
df$text %>%
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
gsub("[[:digit:]]", "", .) %>%         #remove digits
tolower() %>%                          #convert to lower case
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
}
make_dtm <- function(df){
df$text%>%
DocumentTermMatrix(VCorpus(VectorSource()),
control = list(stemming = TRUE )) #needed?
}
