gsub("\n"," ", .)%>%                      #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
#remove hashtags
gsub("[[:digit:]]", "", .) %>%         #remove digits
tolower() %>%                          #convert to lower case
removeWords(., stopwords("en")) %>%    #remove standard stopwords
removeWords(.,tolower(ticker_symbol))
View(ticker_symbol)
ticker_symbol <- supported_tickers()%>%
filter(exchange == "AMEX" | exchange == "NASDAQ" | exchange == "NYSE" )%>%
select(ticker)
View(ticker_symbol)
tw_df$text %>%
gsub("\n"," ", .)%>%                      #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
#remove hashtags
gsub("[[:digit:]]", "", .) %>%         #remove digits
tolower() %>%                          #convert to lower case
removeWords(., stopwords("en")) %>%    #remove standard stopwords
removeWords(.,tolower(ticker_symbol))
ticker_symbol <- supported_tickers()%>%
filter(exchange == "AMEX" | exchange == "NASDAQ" | exchange == "NYSE" )%>%
select(ticker)%>%
as.vector()
View(ticker_symbol)
ticker_symbol <- supported_tickers()%>%
filter(exchange == "AMEX" | exchange == "NASDAQ" | exchange == "NYSE" )%>%
select(ticker)%>%
as.matrix()%>%
as.vector()
ticker_symbol[1:3]
tw_df$text %>%
gsub("\n"," ", .)%>%                      #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
#remove hashtags
gsub("[[:digit:]]", "", .) %>%         #remove digits
tolower() %>%                          #convert to lower case
removeWords(., stopwords("en")) %>%    #remove standard stopwords
removeWords(.,tolower(ticker_symbol))%>%#remove tickers
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
#gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()
ticker_symbol <- supported_tickers()%>%
filter(exchange == "AMEX" | exchange == "NASDAQ" | exchange == "NYSE" )%>%
select(ticker)%>%
as.matrix()%>%
as.vector()%>%
paste("$", .)
ticker_symbol[1:3]
ticker_symbol <- supported_tickers()%>%
filter(exchange == "AMEX" | exchange == "NASDAQ" | exchange == "NYSE" )%>%
select(ticker)%>%
as.matrix()%>%
as.vector()%>%
paste0("$", .)
ticker_symbol[1:3]
ticker_symbol <- supported_tickers()%>%
filter(exchange == "AMEX" | exchange == "NASDAQ" | exchange == "NYSE" )%>%
select(ticker)%>%
as.matrix()%>%
as.vector()%>%
paste0("$", .)%>%
tolower()
ticker_symbol[1:3]
tw_df$text %>%
gsub("\n"," ", .)%>%                      #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
#remove hashtags
gsub("[[:digit:]]", "", .) %>%         #remove digits
tolower() %>%                          #convert to lower case
removeWords(., stopwords("en")) %>%    #remove standard stopwords
removeWords(.,ticker_symbol)%>%#remove tickers
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
#gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()
class(tw_df$hashtags)
VectorSource(tw_df$hashtags)
Corpus(VectorSource(tw_df$hashtags))
DocumentTermMatrix(Corpus(VectorSource(tw_df$hashtags)))
a <- DocumentTermMatrix(Corpus(VectorSource(tw_df$hashtags)))
a
View(a)
a <- DocumentTermMatrix(Corpus(VectorSource(tw_df$hashtags)))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
a
a <- DocumentTermMatrix(Corpus(VectorSource(tw_df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
a
extract_hashtage <- function(df){
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
}
extra_hashtage <- function(df){
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
}
extra_hashtage(tw_df$hashtags)
is.vector(extra_hashtage(tw_df$hashtags))
cleaning_tw_df <- function(df){
extra_hashtage <-
df$hastags%>%
DocumentTermMatrix(Corpus(VectorSource(.)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
df$symbols%>%
DocumentTermMatrix(Corpus(VectorSource(.)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .)                      #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtage)          #remove hashtags
removeWords(.,extra_ticker)            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
}
cleaning_tw_df(tw_df)
cleaning_tw_df <- function(df){
extra_hashtag <-
df$hashtags%>%
DocumentTermMatrix(Corpus(VectorSource()),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
df$symbols%>%
DocumentTermMatrix(Corpus(VectorSource()),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .)                      #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtage)          #remove hashtags
removeWords(.,extra_ticker)            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
}
cleaning_tw_df(tw_df)
cleaning_tw_df(tw_df)
extra_hashtag <-
tw_df$hashtags%>%
DocumentTermMatrix(Corpus(VectorSource(.)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
tw_df$hashtags%>%
DocumentTermMatrix(Corpus(VectorSource()),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
tw_df$hashtags%>%
DocumentTermMatrix(Corpus(VectorSource(.)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_hashtage <- function(df){
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
}
library(shiny)
library(rtweet)
library(tidyquant)
library(tidyverse)
library(dplyr)
library(SentimentAnalysis)
library(ggplot2)
library(wordcloud)
library(edgar)
library(edgarWebR)
library(riingo)
library(anytime)
library(tm)
library(wordcloud)
extra_hashtag <- function(df){
DocumentTermMatrix(Corpus(VectorSource(df)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
}
extra_hashtag(tw_df$hashtags)
extra_hash <-
tw_df$hashtags%>%
DocumentTermMatrix(Corpus(VectorSource()),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_hash <-
tw_df$hashtags%>%
DocumentTermMatrix(Corpus(VectorSource(.)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_hash <-
DocumentTermMatrix(Corpus(VectorSource(tw_df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(tw_df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .)                      #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)           #remove hashtags
removeWords(.,extra_ticker)            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
}
cleaning_tw_df(tw_df)
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)           #remove hashtags
removeWords(.,extra_ticker)            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
}
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)           #remove hashtags
removeWords(.,extra_ticker)            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
}
cleaning_tw_df(tw_df)
cleaning_tw_df(tw_df)
View(tw_df)
cleaning_tw_df(tw_df)
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(tw_df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(tw_df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(tw_df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker
tw_df$text %>%
gsub("\n"," ", .)
tw_df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .)
tw_df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)           #remove hashtags
removeWords(.,extra_ticker)            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()
tw_df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(extra_hashtag)           #remove hashtags
removeWords(extra_ticker)            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)%>%           #remove hashtags
removeWords(.,extra_ticker)%>%            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
}
cleaning_tw_df(tw_df)
cleaned_tw
cleaning_tw_df <- function(df){
extra_hashtag <-
DocumentTermMatrix(Corpus(VectorSource(df$hashtags)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
extra_ticker <-
DocumentTermMatrix(Corpus(VectorSource(df$symbols)),
control = list( removePunctuation = T,
stripWhitespace = T,
tolower = T ))%>%
as.matrix()%>%
as.data.frame()%>%
colnames()
cleaned_tw <-
df$text %>%
gsub("\n"," ", .) %>%                  #remove \n
#remove urls
gsub("[[:punct:]]", " ", .) %>%        #remove punctuation
tolower() %>%                          #convert to lower case
removeWords(.,extra_hashtag)%>%           #remove hashtags
removeWords(.,extra_ticker)%>%            #remove tickers symbols
gsub("[[:digit:]]", "", .) %>%         #remove digits
removeWords(., stopwords("en")) %>%    #remove standard stopwords
gsub('\\b\\w{1,2}\\b','', .) %>%       #remove words of length 1-2
gsub('\\b\\w{21,}\\b','', .) %>%       #remove words of length 21 or more
gsub("\\s(\\s*)", " ", .) %>%          #remove excess whitespace
trimws()                               #remove first space
print(cleaned_tw)
}
cleaning_tw_df(tw_df)
rm(q,q1,q2,t,t1,t2,token,tttt)
rm(q,q1,q2,t,t1,t2,token,tttt)
